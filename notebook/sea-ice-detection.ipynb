{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sea-Ice Detection with Micron Sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import external libraries\n",
    "import csv\n",
    "import datetime\n",
    "import dateutil\n",
    "import dill\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns \n",
    "import sys\n",
    "from matplotlib import pyplot as plt \n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "# add parent directory to the path for importing modules \n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import micron_reader\n",
    "import micron_plotter\n",
    "import MicronEnsemble\n",
    "import MicronTimeSeries\n",
    "\n",
    "# use Seaborn settings for plotting \n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Reload Modules and Initialize Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_modules():\n",
    "    importlib.reload(MicronEnsemble)\n",
    "    importlib.reload(MicronTimeSeries)\n",
    "    importlib.reload(micron_reader)\n",
    "    importlib.reload(micron_plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fri_24_Jan_13_34': [('label_ice_category', 0, -180, -3.5, 1.0),\n",
       "  ('label_ice_presence', 0, -180, -3.5, 1.0),\n",
       "  ('label_ice_percent', 0, -180, -3.5, 1.0),\n",
       "  ('label_ice_category', 22, -3.5, 180, 1.0),\n",
       "  ('label_ice_presence', 1, -3.5, 180, 1.0),\n",
       "  ('label_ice_percent', 1, -3.5, 180, 1.0),\n",
       "  ('label_ice_thickness', 6.5, -3.5, 180, 1.0)],\n",
       " 'Fri_24_Jan_14_30': [('label_ice_category', 10, -180, -3.0, 1.0),\n",
       "  ('label_ice_presence', 1, -180, -3.0, 1.0),\n",
       "  ('label_ice_percent', 0.1, -180, -3.0, 1.0),\n",
       "  ('label_ice_category', 22, -3.0, 180, 1.0),\n",
       "  ('label_ice_presence', 1, -3.0, 180, 1.0),\n",
       "  ('label_ice_percent', 1, -3.0, 180, 1.0),\n",
       "  ('label_ice_thickness', 6.5, -3.0, 180, 1.0)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_dict = {}\n",
    "\n",
    "# open labeled data if not initiated yet \n",
    "try:\n",
    "    labeled_data\n",
    "except NameError:\n",
    "    with open('labeled_data', 'rb') as pickle_file:\n",
    "        labeled_data = dill.load(pickle_file)\n",
    "        labeled_data\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Parse Micron Sonar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: Fri_24_Jan_14_30.CSV\n",
      "  >> Ensembles Parsed:   100\n",
      "  >> Ensembles Parsed:   200\n",
      "  >> Ensembles Parsed:   300\n",
      "  >> Ensembles Parsed:   400\n",
      "  >> Ensembles Parsed:   500\n",
      "  >> Ensembles Parsed:   600\n",
      "  >> Ensembles Parsed:   700\n",
      "  >> Ensembles Parsed:   800\n",
      "  >> Ensembles Parsed:   900\n",
      "  >> Ensembles Parsed:  1000\n",
      "  >> Ensembles Parsed:  1100\n",
      "  >> Ensembles Parsed:  1200\n",
      "  >> Ensembles Parsed:  1300\n",
      "  >> Ensembles Parsed:  1400\n",
      "  >> Ensembles Parsed:  1500\n",
      "  >> Ensembles Parsed:  1600\n",
      "  >> Ensembles Parsed:  1700\n",
      "  >> Ensembles Parsed:  1800\n",
      "  >> Ensembles Parsed:  1900\n",
      "  >> Ensembles Parsed:  2000\n",
      "  >> Ensembles Parsed:  2100\n",
      "  >> Ensembles Parsed:  2200\n",
      "  >> Ensembles Parsed:  2300\n",
      "  >> Ensembles Parsed:  2400\n",
      "  >> Finished Parsing!\n"
     ]
    }
   ],
   "source": [
    "reload_modules()\n",
    "file_list = [\n",
    "    \"Fri_24_Jan_13_34\",\n",
    "    \"Fri_24_Jan_14_30\",\n",
    "    \"Fri_24_Jan_14_42\",\n",
    "    \"Fri_24_Jan_14_55\",\n",
    "    \"Fri_24_Jan_15_08\",\n",
    "    \"Fri_24_Jan_15_20\",\n",
    "    \"Fri_24_Jan_15_33\",\n",
    "    \"Fri_24_Jan_15_50\"\n",
    "]\n",
    "file     = file_list[1]\n",
    "ext      = \".CSV\"\n",
    "folder   = \"2020-01-24_WHOI-Tank-Sonar-Testing/csv/\"\n",
    "root     = \"/Users/zduguid/Dropbox (MIT)/MIT-WHOI/NSF Arctic NNA/Research Activities/\"\n",
    "filepath = \"%s%s%s%s\" % (root, folder, file, ext)\n",
    "location = \"Woods Hole MA\"\n",
    "date     = (2020, 1, 24)\n",
    "\n",
    "constant_depth = 0.4\n",
    "\n",
    "time_series_dict[file] = micron_reader.micron_reader(\n",
    "    filepath, \n",
    "    location=location, \n",
    "    date=date,\n",
    "    bearing_bias=0,\n",
    "    constant_depth=constant_depth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Define Separator and Set Ice Labels Appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_labels_and_plot(set_new_labels=False, \n",
    "                        make_polar_plot=True, \n",
    "                        make_incidence_plot=True):\n",
    "    reload_modules()\n",
    "    # playing with separator \n",
    "    min_bearing = -180\n",
    "    max_bearing =  180\n",
    "    separator   =  -2.5\n",
    "    pad         =   1.0\n",
    "\n",
    "\n",
    "    # generate polar plot \n",
    "    if make_polar_plot:\n",
    "        micron_plotter.plot_polar(time_series_dict[file], \n",
    "                                  separator=separator, \n",
    "                                  pad=pad,\n",
    "                                  output_file=file+\"_polar\")\n",
    "\n",
    "\n",
    "    # hand-annotated labels to add to this data \n",
    "    labels = [\n",
    "        # open water side \n",
    "        ('label_ice_category',   10, min_bearing, separator,   pad),\n",
    "        ('label_ice_presence',    1, min_bearing, separator,   pad),\n",
    "        ('label_ice_percent',   0.1, min_bearing, separator,   pad),\n",
    "    #     ('label_ice_category',    0, min_bearing, separator,   pad),\n",
    "    #     ('label_ice_presence',    0, min_bearing, separator,   pad),\n",
    "    #     ('label_ice_percent',     0, min_bearing, separator,   pad),\n",
    "        # ice slab side\n",
    "        ('label_ice_category',   22, separator,   max_bearing, pad),\n",
    "        ('label_ice_presence',    1, separator,   max_bearing, pad),\n",
    "        ('label_ice_percent',     1, separator,   max_bearing, pad),\n",
    "        ('label_ice_thickness', 6.5, separator,   max_bearing, pad)\n",
    "    ]\n",
    "\n",
    "\n",
    "    # reset labels and then add labels listed above\n",
    "    time_series_dict[file].reset_labels()\n",
    "    for (var, val, b_min, b_max, pad) in labels:\n",
    "        time_series_dict[file].set_label_by_bearing(var, val, b_min, b_max, pad)\n",
    "\n",
    "    # plot incidence vs intensity curve\n",
    "    if make_incidence_plot:\n",
    "        micron_plotter.plot_incidence_curves(time_series_dict[file], \n",
    "                                             variable_size=False,\n",
    "                                             output_file=file+\"_incidence\",\n",
    "                                             axis_limits=True)\n",
    "\n",
    "    # add labels to label dictionary \n",
    "    if file not in labeled_data:\n",
    "        labeled_data[file] = labels\n",
    "    elif set_new_labels:\n",
    "        labeled_data[file] = labels\n",
    "    else:\n",
    "        print(\"WARNING: cannot set new labeled data for this file\")\n",
    "\n",
    "    max_intensity_norm = np.max(time_series_dict[file].df.max_intensity_norm)\n",
    "    if max_intensity_norm > 20:\n",
    "        print(\"WARNING: some values are not plotting, max norm is: %f\" % (max_intensity_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_labels_and_plot(set_new_labels=False,\n",
    "#                     make_polar_plot=True,\n",
    "#                     make_incidence_plot=True)\n",
    "\n",
    "set_labels_and_plot(set_new_labels=True,\n",
    "                    make_polar_plot=False,\n",
    "                    make_incidence_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('max gain', 2.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'max gain', np.max(time_series_dict[file].df.gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Combine Time Series Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('time_series_dict', 'wb') as pickle_file:\n",
    "#     dill.dump(time_series_dict, pickle_file)\n",
    "    \n",
    "# with open('labeled_data', 'wb') as pickle_file:\n",
    "#     dill.dump(labeled_data, pickle_file)\n",
    "\n",
    "print(len(time_series_dict))\n",
    "time_series_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Log Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fri_24_Jan_13_34': [('label_ice_category', 0, -180, -4.0, 1.0),\n",
       "  ('label_ice_presence', 0, -180, -4.0, 1.0),\n",
       "  ('label_ice_percent', 0, -180, -4.0, 1.0),\n",
       "  ('label_ice_category', 22, -4.0, 180, 1.0),\n",
       "  ('label_ice_presence', 1, -4.0, 180, 1.0),\n",
       "  ('label_ice_percent', 1, -4.0, 180, 1.0),\n",
       "  ('label_ice_thickness', 6.5, -4.0, 180, 1.0)],\n",
       " 'Fri_24_Jan_14_30': [('label_ice_category', 10, -180, -2.5, 1.0),\n",
       "  ('label_ice_presence', 1, -180, -2.5, 1.0),\n",
       "  ('label_ice_percent', 0.1, -180, -2.5, 1.0),\n",
       "  ('label_ice_category', 22, -2.5, 180, 1.0),\n",
       "  ('label_ice_presence', 1, -2.5, 180, 1.0),\n",
       "  ('label_ice_percent', 1, -2.5, 180, 1.0),\n",
       "  ('label_ice_thickness', 6.5, -2.5, 180, 1.0)]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# RANDOM TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micron Beam Cross-Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.5)\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "res        = 50\n",
    "r_min      = 1 \n",
    "deg_to_rad = np.pi/180\n",
    "\n",
    "def f(phi,theta):\n",
    "    return(r_min/np.cos(phi*deg_to_rad)/np.cos(theta*deg_to_rad))\n",
    "\n",
    "# define the coordinate system of the traced beam\n",
    "v_angle = 35\n",
    "h_angle = 3 \n",
    "v_width = np.linspace(-(v_angle/2), (v_angle/2), res)\n",
    "h_width = np.linspace(-(h_angle/2), (h_angle/2), res)\n",
    "\n",
    "# set up meshgrid \n",
    "X,Y     = np.meshgrid(v_width,h_width)\n",
    "Z = np.zeros((res,res))\n",
    "for i in range(res):\n",
    "    for j in range(res):\n",
    "        Z[i,j] = f(X[i,j],Y[i,j])\n",
    "\n",
    "print(np.max(Z))\n",
    "print(np.min(Z))\n",
    "print(np.mean(Z))\n",
    "print(np.median(Z))\n",
    "        \n",
    "img = plt.pcolor(X, Y, Z, cmap='viridis')\n",
    "fig.colorbar(img)\n",
    "ax.axis('equal')\n",
    "ax.set_title('Slant Range Multiplier for Micron Sonar Beam', \n",
    "             fontsize=22, fontweight='bold')\n",
    "ax.set_xlabel('Vertical Angle [deg]')\n",
    "ax.set_ylabel('Horizontal Angle [deg]')\n",
    "# plt.savefig(\"../figs/%s.png\" % ('slant-range-multiplier'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.5)\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "# # normalizing between zero and 1 \n",
    "# time_series.df['max_intensity']/np.max(time_series.df['max_intensity'])\n",
    "# time_series.df['max_intensity_norm']/np.max(time_series.df['max_intensity_norm'])\n",
    "\n",
    "ax.plot(time_series_dict[file].df['bearing'], \n",
    "        time_series_dict[file].df['max_intensity'],\n",
    "        'o', color='tab:blue')\n",
    "\n",
    "ax.plot(time_series_dict[file].df['bearing'], \n",
    "        time_series_dict[file].df['max_intensity_norm'],\n",
    "        'o', color='tab:purple')\n",
    "\n",
    "ax.plot(time_series_dict[file].df['bearing'], \n",
    "        time_series_dict[file].df['vertical_range']*10,\n",
    "        'o', color='tab:orange')\n",
    "\n",
    "ax.set_title('Micron Sonar Time Series: Effect of Normalizing Max Intensity', \n",
    "             fontsize=22, fontweight='bold')\n",
    "\n",
    "plt.axvspan(separator-0.1, separator+0.1, color='k')\n",
    "\n",
    "ax.set_xlabel('Bearing [deg]')\n",
    "# ax.set_ylabel('Intensity [dB], Norm Intensity[dB$\\cdot$m]')\n",
    "ax.legend(['Max Intensity [dB]', \n",
    "           'Max Intensity Norm [dB$\\cdot$m]', \n",
    "           'Distance [0.1$\\cdot$m]'], loc='best')\n",
    "# plt.savefig(\"../figs/%s.png\" % ('normalized-intensity6'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.set(font_scale = 1.5)\n",
    "fig, ax = plt.subplots(3,figsize=(15,15))\n",
    "ax[0].plot(time_series.df['bearing_ref_world']-90, time_series.df['peak_start']*np.cos((time_series.df['bearing_ref_world']-90)*np.pi/180), 'o')\n",
    "ax[0].set_xlabel('Incidence Angle [deg]')\n",
    "ax[0].set(xlabel='Incidence Angle [deg]')\n",
    "ax[0].set_xlabel('Peak Width [m]')\n",
    "ax[1].plot(time_series.df['incidence_angle'], time_series.df['max_intensity']*time_series.df['max_intensity_bin'],'o')\n",
    "ax[0].set_xlabel('Incidence Angle [deg]')\n",
    "ax[0].set_xlabel('Max Intensity [db]')\n",
    "ax[2].plot(time_series.df['max_intensity']/time_series.df['max_intensity_bin'], time_series.df['peak_width'], 'o')\n",
    "ax[0].set_xlabel('Max Intensity [db]')\n",
    "ax[0].set_xlabel('Peak Width [m]')\n",
    "# plt.savefig(\"../figs/%s.png\" % ('tmp2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Ice Thickness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.5)\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "plt.plot(time_series.df.bearing_ref_world, time_series.df.peak_start, 'o', color='tab:blue')\n",
    "plt.plot(time_series.df.bearing_ref_world, time_series.df.vertical_range, 'o', color='tab:orange')\n",
    "\n",
    "ax.set_title('Micron Sonar Blake Tank Test: Slant Range and Vertical Range', \n",
    "             fontsize=22, fontweight='bold')\n",
    "\n",
    "plt.axvspan(separator-0.1, separator+0.1, color='k')\n",
    "\n",
    "# water = 0.42\n",
    "ice   = 0.35962075787747666\n",
    "std   = 0.02\n",
    "# plt.axhspan(water-0.001, water+0.001, color='k')\n",
    "# plt.axhspan(ice-std,     ice+std, color='tab:purple', alpha=0.5)\n",
    "window = 10\n",
    "\n",
    "water_edge = time_series.df[(time_series.df.bearing_ref_world > -window) &\n",
    "                            (time_series.df.bearing_ref_world <  separator)]\n",
    "ice_edge   = time_series.df[(time_series.df.bearing_ref_world >  separator) &\n",
    "                            (time_series.df.bearing_ref_world <  window)]\n",
    "\n",
    "water_dist = np.median(water_edge.vertical_range)\n",
    "ice_dist   = np.median(ice_edge.vertical_range)\n",
    "print(water_dist)\n",
    "print(ice_dist)\n",
    "print(water_dist-ice_dist)\n",
    "print()\n",
    "print(np.std(water_edge.vertical_range))\n",
    "print(np.std(ice_edge.vertical_range))\n",
    "\n",
    "plt.plot(water_edge.bearing_ref_world, water_edge.vertical_range, 'o', color='tab:red')\n",
    "plt.plot(ice_edge.bearing_ref_world, ice_edge.vertical_range, 'o', color='tab:green')\n",
    "ax.set_xlabel('Bearing [deg]')\n",
    "ax.set_ylabel('Distance [m]')\n",
    "ax.legend(['Slant Range [m]', \n",
    "           'Vertical Range [m]'], loc='best')\n",
    "# plt.savefig(\"../figs/%s.png\" % ('ice-thickness-6.5cm'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Ensembles to Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    # store current angle and rounded angle \n",
    "    angle_current         = data_array[data_lookup['Bearing']]\n",
    "    angle_current_rounded = math.floor(angle_current/angle_increment)*angle_increment\n",
    "    \n",
    "    # TODO make this a sub-method\n",
    "    # compute the change in angle since a plot has been generated \n",
    "    if (not angle_previous): \n",
    "        angle_delta = 0\n",
    "    else:  \n",
    "        # add change current angle difference to the running sum since last plot \n",
    "        if angle_current - angle_previous > 0:\n",
    "            angle_delta += angle_current - angle_previous \n",
    "        # account for instance where \n",
    "        else: \n",
    "            angle_delta += angle_current + deg_in_circle - angle_previous \n",
    "    \n",
    "    # update previous angle \n",
    "    angle_previous = angle_current \n",
    "    \n",
    "    # generate plot for every 20 degrees, avoid replotting area already plotted\n",
    "    if ((angle_current_rounded % angle_increment == 0) and \n",
    "        (angle_delta > angle_increment/2) and \n",
    "        (angle_current_rounded not in angles_plotted) and \n",
    "        (plot_on)):\n",
    "\"\"\"\n",
    "z = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with Bit-Encoding of Micron Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(\"8923\", 16)\n",
    "int(\"16\", 16)\n",
    "bin(int(\"16\", 16))\n",
    "bin(8923)\n",
    "\n",
    "bin(16971)[2:][::-1]\n",
    "int('1101001001000010'[::-1],2)\n",
    "\n",
    "# 8923 hex -> 0b   1000 1001 0010 0011\n",
    "# 8923 int -> 0b   0010 0010 1101 1011'\n",
    "\n",
    "# 8967 hex -> 0b   1000 1001 0110 0111\n",
    "# 8967 int -> 0b   0010 0011 0000 0111'\n",
    "\n",
    "# 144  hex -> 0b 1 0100 0100\n",
    "# 144  int -> 0b   1001 0000\n",
    "# 16   hex -> 0b   0001 0110\n",
    "\n",
    "# print(header[14], row1[14]) # column 14 is the number of data points in the scanline \n",
    "# print(header[15], row1[15]) # column 15 is the first value of an array DBytes long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
